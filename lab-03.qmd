---
title: "lab 3: COVID-19"
subtitle: 'Ecosystem Science and Sustainability 330'
author:
  - name: Megan Hoover
    email: megan.hoover21@gmail.com
format: html
execute: 
  echo: true
output:
  html
    self contained:true
knitr:
  opts_chunk:
    collapse: true
    comment: "#>"
---

## Q2: Lets pretend it in January 1st, 2022. You are a data scientist for the state of Colorado Department of Public Health.

You’ve been tasked with giving a report to Governor Polis each morning about the most current COVID-19 conditions at the county level.

As it stands, the Colorado Department of Public Health maintains a watch list of counties that are being monitored for worsening corona virus trends. There are six criteria used to place counties on the watch list:

1.Doing fewer than 150 tests per 100,000 residents daily (over a 7-day average)
2.More than 100 new cases per 100,000 residents over the past 14 days…
3.25 new cases per 100,000 residents and an 8% test positivity rate
4.10% or greater increase in COVID-19 hospitalized patients over the past 3 days
5.Fewer than 20% of ICU beds available
6.Fewer than 25% ventilators available 
Of these 6 conditions, you are in charge of monitoring condition number 2.

To do this job well, you should set up a reproducible framework to communicate the following in a way that can be updated every time new data is released (daily):

1. cumulative cases in the 5 worst counties
2. total NEW cases in the 5 worst counties
3. A list of safe counties
4. A text report describing the total new cases, total cumulative cases, and number of safe counties.
You should build this analysis in such a way that running it will extract the most current data straight from the NY-Times URL and the state name and date are parameters that can be changed allowing this report to be run for other states/dates.

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r} 
#Download libraries,read in COVID-19 Data, and prepare data table for calculations
library(tidyverse) #data wrangling and visualization) 

library(flextable) #make nice tables)

library(zoo) #(rolling averages

url = 'https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv'
covid_raw<-read_csv(url)

#create my.date and my.state object. Set my date to "2022-02-01" and my state to "colorado"
my.date <- "2022-02-01" 
  class(my.date)
date<-my.date %>%
  as.Date()
class(date)
my.state <- "Colorado"

#Start by making a subset that limits (filter) the data to Colorado and add a new column (mutate) with the daily new cases using diff/lag by county (group_by). Do the same for new deaths as well.

#(Hint: you will need some combination of filter, group_by, arrange, mutate, diff/lag, and ungroup)

covid1 = covid_raw %>%
  filter(state == my.state) %>%
  arrange(county, date) %>%
  group_by(county) %>%
  mutate(
    new_cases = cases - lag(cases, order_by = date),
    new_deaths = deaths - lag(deaths, order_by = date)
  ) %>%
  ungroup()

head(covid1)
```

# filter the data to include only records for the date my.date, which is 2022-02-01.
```{r}
top_cum_cases <- covid1 %>%
  filter(date== my.date) %>%
  arrange(desc(cases)) %>%
  select(county, cases) %>%
  head(5)

top_new_cases <- covid1 %>%
  filter(date== my.date) %>%
  arrange(desc(new_cases)) %>%
  select(county, new_cases) %>%
  head(5)
```

# Using your subset, generate (2) tables. The first should show the 5 counties with the most CUMULATIVE cases, and the second should show the 5 counties with the most NEW cases. Remember to use your my.date object as a proxy for today’s date:
```{r}
flex_top_cumcases = flextable(top_cum_cases)
  flex_top_cumcases %>%
  set_caption("Top 5 Counties with the Most Cumulative Cases as of 2022-02-01")
  
print(flex_top_cumcases)

flex_new_cases = flextable(top_new_cases)
flex_new_cases %>% 
  set_caption("Top 5 Counties with the Most New Cases as of 2022-02-01")

print(flex_new_cases)

```

# Population data is offered by the Census. Please read in this data.
```{r}
pop_url <- 'https://www2.census.gov/programs-surveys/popest/datasets/2020-2023/counties/totals/co-est2023-alldata.csv'

pop_covid_raw <-read_csv(pop_url)
```

# You notice that the COVID data provides a 5 digit character FIP code representing the state in the first 2 digits and the county in the last 3. In the population data, the STATE and COUNTY FIP identifiers are read in as numerics. To make these compatible we need to:

1.Convert the STATE numeric into a character forced to 2 digits with a leading 0 (when needed)
2.Convert the COUNTY numeric into a character forced to 3 digits with leading 0’s (when needed)
3.Create a FIP variable the STATE numeric into a character forced to 2 digits with a leading 0 (when needed)
```{r}
#convert state numeric into a character forced to 2 digits w/ a leading 0
#We can use the sprintf() function in base R to add leading zeros. The sprintf() function is powerful and versatile for string formatting.

#pop_covid1<- pop_covid_raw %>%
 # mutate(state_fips = sprintf("%02s", STATE), # This ensures state is two digits 
        # county_fips = sprintf("%03s", COUNTY)) %>%#This ensures county is 3 digits
      # mutate(fips_code = paste(state_fips, county_fips, sep = ""))                         

```


# Q 3.1: Given the above URL, and guidelines on string concatenation and formatting, read in the population data and (1) create a five digit FIP variable and only keep columns that contain “NAME” or “2021” (remember the tidyselect option found with ?dplyr::select). Additionally, remove all state level rows (e.g. COUNTY FIP == “000”)
```{r}
pop_covid1 <- pop_covid1 %>%
  filter(COUNTY != "000") %>% 
  mutate(state_fips = sprintf("%02s", STATE), #for character use %02s
         county_fips = sprintf("%03s", COUNTY)) %>%
  mutate(fips_code = paste(state_fips, county_fips, sep = "")) %>% #taking state and county fips and combinging into new column
  select(fips_code, contains("NAME"), contains("2021")) #selecting only flips_code with all the name parameters and year 2021
```

# Q 3.2: Now, explore the data … what attributes does it have, what are the names of the columns? Do any match the COVID data we have? What are the dimensions… In a few sentences describe the data obtained after modification:
```{r}
#Hint: names(), dim(), nrow(), str(), glimpse, skimr,…
# Explore the population data
names(pop_covid1)
dim(pop_covid1)
nrow(pop_covid1)
str(pop_covid1)
glimpse(pop_covid1)
install.packages("skimr")
library(skimr)
skimr::data_cols(pop_covid1)
```
# The covid1 data set contains a tbl_df. tbl, and data.frame class, with 3,144 rows and 19 columns.
The names of the the columns are:
[1] "fips_code"             "STNAME"               
 [3] "CTYNAME"               "POPESTIMATE2021"      
 [5] "NPOPCHG2021"           "BIRTHS2021"           
 [7] "DEATHS2021"            "NATURALCHG2021"       
 [9] "INTERNATIONALMIG2021"  "DOMESTICMIG2021"      
[11] "NETMIG2021"            "RESIDUAL2021"         
[13] "GQESTIMATES2021"       "RBIRTH2021"           
[15] "RDEATH2021"            "RNATURALCHG2021"      
[17] "RINTERNATIONALMIG2021" "RDOMESTICMIG2021"     
[19] "RNETMIG2021"

The raw covid data matches some of the data in the pop_covid1 columns. Those columns are "fips_code", "STNAME", "CTYNAME".

The dimensions of the pop_covid1 data set are 3144 rows and 19 columns.

# Q 3.3: What is the range of populations seen in Colorado counties in 2021?
```{r}
# Get the range of populations for Colorado counties in 2021
pop_covid1 %>%
  filter(str_detect(STNAME, "Colorado")) %>%
  summarise(min(POPESTIMATE2021),max(POPESTIMATE2021))

```
# The min population of Colorado counties in 2021 is 741 people and the max is 737, 287 people.

# Q 3.4: Join the population data to the Colorado COVID data and compute the per capita cumulative cases, per capita new cases, and per capita new deaths:
```{r}
covid1<-covid1 %>%
  rename(fips_code=fips) #rename fips column to match column name in pop_covid1
# Merge with the Covid1 data, which has state set to Co

merged_data <- covid1 %>%
  left_join(pop_covid1, by = "fips_code") #joining covid data on the left to the pop_covid 1

# Calculate per per capita cumulative cases, per capita cases, and new deaths
merged_data <- merged_data %>%
  mutate(
    cumulative_cases_percapita = cases / POPESTIMATE2021 * 100000,
    newcases_per_capita = new_cases / POPESTIMATE2021 * 100000,
    new_deaths_per_capita = deaths / POPESTIMATE2021* 100000
  )
```

# Q 3.5: Generate (2) new tables. The first should show the 5 counties with the most cumulative cases per capita on 2021-01-01, and the second should show the 5 counties with the most NEW cases per capita on the same date. Your tables should have clear column names and descriptive captions.
(Hint: Use `flextable::flextable() and flextable::set_caption())
```{r}
# Table 1: Top 5 counties with the most cumulative cases per capita
top_cumulative_cases_per_capita <- merged_data %>%
  filter(date == "2021-01-01") %>%
  arrange(desc(cumulative_cases_percapita)) %>%
  select(county, cumulative_cases_percapita) %>%
  head(5)
  
  top_cum_cases_per_cap_flex<- flextable(top_cumulative_cases_per_capita) %>%
  set_caption("Top 5 Counties with the Most Cumulative Cases Per Capita on 2021-01-01")
  
  print(top_cum_cases_per_cap_flex)
```
```{r}
# Table 2: Top 5 counties with the most new cases per capita
top_new_cases_per_capita <- merged_data %>%
  filter(date=="2021-01-01") %>%
  arrange(desc(newcases_per_capita)) %>%
  select(county, newcases_per_capita) %>%
  head(5)

top_new_cases_per_cap_flex<- flextable(top_new_cases_per_capita) %>%
  set_caption("Top 5 Counties with the Most New Cases Per Capita on 2021-01-01")
  
  print(top_new_cases_per_cap_flex)
```


